<?xml version="1.0" encoding="utf-8"?>
<qroot>
<question>
<Title>Parallel computing in python significantly slower than regular for loop</Title>
<Body>&lt;p&gt;So I&#x27;m trying to do some simple image analysis in python, I have a numpy array of the video in question and it has  a shape of (930, 256, 256), i.e. 930 frames of a resolution of 256 by 256 pixels.&lt;/p&gt;&lt;p&gt;I&#x27;m trying to do seed pixel correlation in parallel, my computer has 12 cores, so I should be able to write a parallel for loop and get my results faster.&lt;/p&gt;&lt;p&gt;This is what I came up with after looking around for ways to write parallel for loops. However, it&#x27;s significantly slower than the non parallel version!!&lt;/p&gt;&lt;p&gt;Perhaps someone can tell me a better way of writing it? (using other libraries!) Or maybe someone can tell me why it is slower?&lt;/p&gt;&lt;p&gt;Here&#x27;s the code I came up with:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import numpy as npfrom scipy.stats.stats import pearsonrfrom joblib import Parallel, delayed  import multiprocessingdef corr(pixel, seed_pixel):    return pearsonr(pixel, seed_pixel)[0]def get_correlation_map(seed_x, seed_y, frames):    seed_pixel = np.asarray(frames[:, seed_x, seed_y], dtype=np.float32)    # Reshape into time and space    frames = np.reshape(frames, (total_number_of_frames, width*height))    #correlation_map = []    #####################################    print &#x27;Getting correlation...&#x27;    # The parallel version.    correlation_map = Parallel(n_jobs=12)(delayed(corr)(pixel, seed_pixel) for pixel in frames.T)    # Non parallel version    #correlation_map = []    #for i in range(frames.shape[-1]):        #correlation_map.append(pearsonr(frames[:, i], seed_pixel)[0])    #####################################    correlation_map = np.asarray(correlation_map, dtype=np.float32)    correlation_map = np.reshape(correlation_map, (width, height))    print np.shape(correlation_map)    return correlation_map&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All I need is a way to parallelize a for loop that will append its results  to a list in the order of the iteration. So I suppose synchronization could be an issue!&lt;/p&gt;</Body>
<Tags>python,numpy,parallel-processing,scipy</Tags>
</question>
<answer>
<Body>&lt;p&gt;You are likely having an issue because the arguments passed to &lt;code&gt;Parallel&lt;/code&gt; are large and all being serialized. You can use &lt;code&gt;backend=&quot;threading&quot;&lt;/code&gt; to avoid this if (as i assume) &lt;code&gt;personr&lt;/code&gt; releases the GIL. Otherwise you might have to look into &lt;code&gt;numpy.memmap&lt;/code&gt; and stick with using &lt;code&gt;multiprocessor&lt;/code&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;correlation_map = Parallel(n_jobs=12, backend=&quot;threading&quot;)(delayed(corr)(pixel, seed_pixel) for pixel in frames.T)&lt;/code&gt;&lt;/pre&gt;</Body>
</answer>
</qroot>
