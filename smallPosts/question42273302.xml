<?xml version="1.0" encoding="utf-8"?>
<qroot>
<question>
<Title>Python (BeautifulSoup) - For Loop returns all results for one div, instead of the one value expected</Title>
<Body>&lt;p&gt;I am creating a Food Hygiene scraper. I have got to the point where I can successfully get the name and addresses of all the restaurants based on what postcode is entered by the user. I have attempted to get the food hygiene rating value to be displayed for each result as well.&lt;/p&gt;&lt;p&gt;This value is stored the following way on the web page:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;div class=&quot;rating-image&quot; style=&quot;clear: right;&quot;&amp;gt;                &amp;lt;a href=&quot;/business/abbey-community-college-newtownabbey-antrim-992915.html&quot; title=&quot;View Details&quot;&amp;gt;                    &amp;lt;img src=&quot;https://images.scoresonthedoors.org.uk//schemes/735/on_small.png&quot; alt=&quot;5 (Very Good)&quot;&amp;gt;                &amp;lt;/a&amp;gt;            &amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I am trying to extract the img alt text&lt;/p&gt;&lt;p&gt;My code is below:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import requestsimport timefrom bs4 import BeautifulSoupclass RestaurantScraper(object):def __init__(self, pc):    self.pc = pc        # the input postcode    self.max_page = self.find_max_page()        # The number of page available    self.restaurants = list()       # the final list of restaurants where the scrape data will at the end of processdef run(self):    for url in self.generate_pages_to_scrape():        restaurants_from_url = self.scrape_page(url)        self.restaurants += restaurants_from_url     # we increment the  restaurants to the global restaurants listdef create_url(self):    &quot;&quot;&quot;    Create a core url to scrape    :return: A url without pagination (= page 1)    &quot;&quot;&quot;    return &quot;https://www.scoresonthedoors.org.uk/search.php?name=&amp;amp;address=&amp;amp;postcode=&quot; + self.pc + \           &quot;&amp;amp;distance=1&amp;amp;search.x=8&amp;amp;search.y=6&amp;amp;gbt_id=0&amp;amp;award_score=&amp;amp;award_range=gt&quot;def create_paginated_url(self, page_number):    &quot;&quot;&quot;    Create a paginated url    :param page_number: pagination (integer)    :return: A url paginated    &quot;&quot;&quot;    return self.create_url() + &quot;&amp;amp;page={}&quot;.format(str(page_number))def find_max_page(self):    &quot;&quot;&quot;    Function to find the number of pages for a specific search.    :return: The number of pages (integer)    &quot;&quot;&quot;    time.sleep(5)    r = requests.get(self.create_url())    soup = BeautifulSoup(r.content, &quot;lxml&quot;)    pagination_soup = soup.findAll(&quot;div&quot;, {&quot;id&quot;: &quot;paginator&quot;})    pagination = pagination_soup[0]    page_text = pagination(&quot;p&quot;)[0].text    return int(page_text.replace(&#x27;Page 1 of &#x27;, &#x27;&#x27;))def generate_pages_to_scrape(self):    &quot;&quot;&quot;    Generate all the paginated url using the max_page attribute previously scraped.    :return: List of urls    &quot;&quot;&quot;    return [self.create_paginated_url(page_number) for page_number in range(1, self.max_page + 1)]def scrape_page(self, url):    &quot;&quot;&quot;    This is coming from your original code snippet. This probably need a bit of work, but you get the idea.    :param url: Url to scrape and get data from.    :return:    &quot;&quot;&quot;    time.sleep(5)    r = requests.get(url)    soup = BeautifulSoup(r.content, &quot;lxml&quot;)    g_data = soup.findAll(&quot;div&quot;, {&quot;class&quot;: &quot;search-result&quot;})    ratings = soup.select(&#x27;div.rating-image img[alt]&#x27;)    restaurants = list()    for item in g_data:        name = print (item.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;name&quot;})[0].text)        restaurants.append(name)        try:            print (item.find_all(&quot;span&quot;, {&quot;class&quot;: &quot;address&quot;})[0].text)        except:            pass        for rating in ratings:            bleh = rating[&#x27;alt&#x27;]            print (bleh)    return restaurantsif __name__ == &#x27;__main__&#x27;:pc = input(&#x27;Give your post code&#x27;)scraper = RestaurantScraper(pc)scraper.run()print (&quot;{} restaurants scraped&quot;.format(str(len(scraper.restaurants))))&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The way I have attempted this to gather each hygiene rating for each restaurant is using a for loop as shown below:&lt;/p&gt;&lt;pre&gt;&lt;code&gt; for rating in ratings:            bleh = rating[&#x27;alt&#x27;]            print (bleh)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The problem is that when the script is run that under the name and address of each restaurant, it displays all of the food hygiene ratings for all restaurants on the page, whereas I need each single rating to be displayed under each single restaurant&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/3qLDv.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;Incorrect output of all ratings being displayed&lt;/a&gt;&lt;/p&gt;&lt;p&gt;I am thinking that this may be an incorrect position of the for loop?&lt;/p&gt;&lt;p&gt;Many thanks to anyone who looks at this, and to anyone who provides guidance &lt;/p&gt;</Body>
<Tags>python,python-3.x,web-scraping,beautifulsoup</Tags>
</question>
<answer>
<Body>&lt;p&gt;Got this working, seems I forgot to add the for loop for the ratings to a try except block. After adding it to this block the single ratings for each restaurant are displayed correctly. &lt;/p&gt;&lt;p&gt;Below is the fully working code&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import requestsimport timefrom bs4 import BeautifulSoupclass RestaurantScraper(object):def __init__(self, pc):    self.pc = pc        # the input postcode    self.max_page = self.find_max_page()        # The number of page available    self.restaurants = list()       # the final list of restaurants where the scrape data will at the end of processdef run(self):    for url in self.generate_pages_to_scrape():        restaurants_from_url = self.scrape_page(url)        self.restaurants += restaurants_from_url     # we increment the  restaurants to the global restaurants listdef create_url(self):    &quot;&quot;&quot;    Create a core url to scrape    :return: A url without pagination (= page 1)    &quot;&quot;&quot;    return &quot;https://www.scoresonthedoors.org.uk/search.php?name=&amp;amp;address=&amp;amp;postcode=&quot; + self.pc + \           &quot;&amp;amp;distance=1&amp;amp;search.x=8&amp;amp;search.y=6&amp;amp;gbt_id=0&amp;amp;award_score=&amp;amp;award_range=gt&quot;def create_paginated_url(self, page_number):    &quot;&quot;&quot;    Create a paginated url    :param page_number: pagination (integer)    :return: A url paginated    &quot;&quot;&quot;    return self.create_url() + &quot;&amp;amp;page={}&quot;.format(str(page_number))def find_max_page(self):    &quot;&quot;&quot;    Function to find the number of pages for a specific search.    :return: The number of pages (integer)    &quot;&quot;&quot;    time.sleep(5)    r = requests.get(self.create_url())    soup = BeautifulSoup(r.content, &quot;lxml&quot;)    pagination_soup = soup.findAll(&quot;div&quot;, {&quot;id&quot;: &quot;paginator&quot;})    pagination = pagination_soup[0]    page_text = pagination(&quot;p&quot;)[0].text    return int(page_text.replace(&#x27;Page 1 of &#x27;, &#x27;&#x27;))def generate_pages_to_scrape(self):    &quot;&quot;&quot;    Generate all the paginated url using the max_page attribute previously scraped.    :return: List of urls    &quot;&quot;&quot;    return [self.create_paginated_url(page_number) for page_number in range(1, self.max_page + 1)]def scrape_page(self, url):    &quot;&quot;&quot;    This is coming from your original code snippet. This probably need a bit of work, but you get the idea.    :param url: Url to scrape and get data from.    :return:    &quot;&quot;&quot;    time.sleep(5)    r = requests.get(url)    soup = BeautifulSoup(r.content, &quot;lxml&quot;)    g_data = soup.findAll(&quot;div&quot;, {&quot;class&quot;: &quot;search-result&quot;})    ratings = soup.select(&#x27;div.rating-image img[alt]&#x27;)    restaurants = list()    for item in g_data:        name = print (item.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;name&quot;})[0].text)        restaurants.append(name)        try:            print (item.find_all(&quot;span&quot;, {&quot;class&quot;: &quot;address&quot;})[0].text)        except:            pass        try:            for rating in ratings:                bleh = rating[&#x27;alt&#x27;]                print (bleh)[0].text        except:            pass    return restaurantsif __name__ == &#x27;__main__&#x27;:pc = input(&#x27;Give your post code&#x27;)scraper = RestaurantScraper(pc)scraper.run()print (&quot;{} restaurants scraped&quot;.format(str(len(scraper.restaurants))))&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The part which solved the problem was this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt; try:        for rating in ratings:            bleh = rating[&#x27;alt&#x27;]            print (bleh)[0].text    except:        passreturn restaurants&lt;/code&gt;&lt;/pre&gt;</Body>
</answer>
</qroot>
