<?xml version="1.0" encoding="utf-8"?>
<qroot>
<question>
<Title>Scraping reviews from tripadvisor</Title>
<Body>&lt;p&gt;Suppose I am scraping a reviews from the url&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.tripadvisor.com/Hotel_Review-g562819-d289642-Reviews-Hotel_Caserio-Playa_del_Ingles_Maspalomas_Gran_Canaria_Canary_Islands.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://www.tripadvisor.com/Hotel_Review-g562819-d289642-Reviews-Hotel_Caserio-Playa_del_Ingles_Maspalomas_Gran_Canaria_Canary_Islands.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;It contents no of pages which contains the reviews which I want to scrape. So how can I scrape the reviews of all the next pages.&lt;/p&gt;&lt;p&gt;I used the below code but still shows only the reviews in first page only! &lt;/p&gt;&lt;pre&gt;&lt;code&gt;from bs4 import BeautifulSoupimport requestsURL_BASE = &quot;https://www.tripadvisor.com/Hotel_Review-g562819-d289642-Reviews-Hotel_Caserio-Playa_del_Ingles_Maspalomas_Gran_Canaria_Canary_Islands.html&quot;MAX_PAGES = 30counter = 0for i in range(1, MAX_PAGES):if i &amp;gt; 1:    url = &quot;%spage/%d/&quot; % (URL_BASE, i)else:    url = URL_BASEreq = requests.get(url)statusCode = req.status_codeif statusCode == 200:    html = BeautifulSoup(req.text, &quot;html.parser&quot;)    resultsoup = html.find_all(&#x27;P&#x27;, {&#x27;class&#x27;: &#x27;partial_entry&#x27;})else:    breakfor review in resultsoup:review_list = review.get_text()print(review_list)&lt;/code&gt;&lt;/pre&gt;</Body>
<Tags>python,python-3.x,python-2.7,beautifulsoup</Tags>
</question>
<answer>
<Body>&lt;p&gt;Based on &lt;a href=&quot;https://github.com/furas/python-examples/tree/master/scrapy/tripadvisor.com&quot; rel=&quot;nofollow noreferrer&quot;&gt;example for &lt;code&gt;scrapy&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Server adds  to url (in any place before &lt;code&gt;.html&lt;/code&gt;)  &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;-or5&lt;/code&gt; to get second page, &lt;/li&gt;&lt;li&gt;&lt;code&gt;-or10&lt;/code&gt; to get third page, &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;etc.&lt;/p&gt;&lt;p&gt;You could even skip words (which are for &lt;code&gt;SEO&lt;/code&gt;) and use only&lt;/p&gt;&lt;pre&gt;&lt;code&gt;https://www.tripadvisor.com/g562819-d289642-or5.htmlhttps://www.tripadvisor.com/g562819-d289642-or10.html&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;to get next pages with reviews.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;from bs4 import BeautifulSoupimport requestsimport re#import webbrowserdef get_soup(url):    headers = {&#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0&#x27;}    r = s.get(url, headers=headers)    #with open(&#x27;temp.html&#x27;, &#x27;wb&#x27;) as f:    #    f.write(r.content)    #    webbrowser.open(&#x27;temp.html&#x27;)    if r.status_code != 200:        print(&#x27;status code:&#x27;, r.status_code)    else:        return BeautifulSoup(r.text, &#x27;html.parser&#x27;)def parse(url, response):    if not response:        print(&#x27;no response:&#x27;, url)        return    # get number of reviews    num_reviews = response.find(&#x27;span&#x27;, class_=&#x27;reviews_header_count&#x27;).text    num_reviews = num_reviews[1:-1] # remove `( )`    num_reviews = num_reviews.replace(&#x27;,&#x27;, &#x27;&#x27;) # remove `,`    num_reviews = int(num_reviews)    print(&#x27;num_reviews:&#x27;, num_reviews, type(num_reviews))    # create template for urls to pages with reviews    url = url.replace(&#x27;.html&#x27;, &#x27;-or{}.html&#x27;)    print(&#x27;template:&#x27;, url)    # load pages with reviews    for offset in range(0, num_reviews, 5):        print(&#x27;url:&#x27;, url.format(offset))        url_ = url.format(offset)        parse_reviews(url_, get_soup(url_))        return # for test only - to stop after first pagedef parse_reviews(url, response):    print(&#x27;review:&#x27;, url)    if not response:        print(&#x27;no response:&#x27;, url)        return    # get every review    for idx, review in enumerate(response.find_all(&#x27;div&#x27;, class_=&#x27;review-container&#x27;)):        item = {            &#x27;hotel_name&#x27;: response.find(&#x27;h1&#x27;, class_=&#x27;heading_title&#x27;).text,            &#x27;review_title&#x27;: review.find(&#x27;span&#x27;, class_=&#x27;noQuotes&#x27;).text,            &#x27;review_body&#x27;: review.find(&#x27;p&#x27;, class_=&#x27;partial_entry&#x27;).text,            &#x27;review_date&#x27;: review.find(&#x27;span&#x27;, class_=&#x27;relativeDate&#x27;)[&#x27;title&#x27;],#.text,#[idx],            &#x27;num_reviews_reviewer&#x27;: review.find(&#x27;span&#x27;, class_=&#x27;badgetext&#x27;).text,            &#x27;reviewer_name&#x27;: review.find(&#x27;span&#x27;, class_=&#x27;scrname&#x27;).text,            &#x27;bubble_rating&#x27;: review.select_one(&#x27;div.reviewItemInline span.ui_bubble_rating&#x27;)[&#x27;class&#x27;][1][7:],        }        results.append(item) # &amp;lt;--- add to global list        #~ yield item        for key,val in item.items():            print(key, &#x27;:&#x27;, val)        print(&#x27;----&#x27;)        #return # for test only - to stop after first review# --- main ---s = requests.Session()start_urls = [    &#x27;https://www.tripadvisor.com/Hotel_Review-g562819-d289642-Reviews-Hotel_Caserio-Playa_del_Ingles_Maspalomas_Gran_Canaria_Canary_Islands.html&#x27;,    #&#x27;https://www.tripadvisor.com/Hotel_Review-g60795-d102542-Reviews-Courtyard_Philadelphia_Airport-Philadelphia_Pennsylvania.html&#x27;,    #&#x27;https://www.tripadvisor.com/Hotel_Review-g60795-d122332-Reviews-The_Ritz_Carlton_Philadelphia-Philadelphia_Pennsylvania.html&#x27;,]results = [] # &amp;lt;--- global list for itemsfor url in start_urls:    parse(url, get_soup(url))import pandas as pddf = pd.DataFrame(results) # &amp;lt;--- convert list to DataFramedf.to_csv(&#x27;output.csv&#x27;)    # &amp;lt;--- save in file&lt;/code&gt;&lt;/pre&gt;</Body>
</answer>
</qroot>
