<?xml version="1.0" encoding="utf-8"?>
<qroot>
<question>
<Title>Apache Ignite inserts extremely slow</Title>
<Body>&lt;p&gt;I&#x27;m attempting to load a large matrix into an Apache Ignite master node running in AWS. The EC2 instance has 128GB of memory and 512GB of disk space.&lt;/p&gt;&lt;p&gt;The matrix is a CSV with 50,000 columns and 15,000 rows. &lt;/p&gt;&lt;p&gt;The loading is extremely slow - the first 150 inserts batch together and take over 30 minutes to work. I am using the Python Thin Client&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import pandas as pdimport pyignitefrom pyignite import Clientclient = Client()client.connect(&#x27;127.0.0.1&#x27;, 10800)print(&#x27;deleting records...&#x27;)client.sql(&#x27;DELETE FROM full_test_table&#x27;)df = pd.read_csv(&#x27;exon.csv&#x27;)col = list(df)col = col[1:]names = &#x27;, &#x27;.join(&#x27;&quot;&#x27; + item + &#x27;&quot;&#x27; for item in col)names = &#x27;name, &#x27; + names#print(names)for index, row in df.iterrows():    print(&#x27;inserting for {0}&#x27;.format(str(row[0])))    row[0] = &#x27;\&quot;{0}\&quot;&#x27;.format(row[0])    row[0] = str(index)    values = &#x27;, &#x27;.join(str(item) for item in row)    sql = &#x27;INSERT INTO full_test_table ({0}) VALUES({1})&#x27;.format(names, values)    client.sql(sql)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I would like to use Python to load the data, as I&#x27;m more familiar with that than Java. This seems unreasonably slow to me - even PostgreSQL can take these inserts in seconds. What&#x27;s the issue?&lt;/p&gt;&lt;p&gt;I&#x27;ve tried the COPY command from CSV as well - that doesn&#x27;t seem to work any faster.&lt;/p&gt;</Body>
<Tags>python,sql,ignite,in-memory-database,key-value-store</Tags>
</question>
<answer>
<Body>&lt;p&gt;I have just tried it from Java, and I can see around 25 inserts per second from JDBC. It is not a horribly high number, but it is much better than 30 minutes that you are showing. Maybe it is a Python client thing.&lt;/p&gt;</Body>
</answer>
<answer>
<Body>&lt;p&gt;As of Ignite 2.7, Python Thin Client, as well as other thin clients, use one of the server nodes as a proxy - usually, the one you set in the connection string. The proxy receives all the requests from the client and directs them to the rest of the servers if needed. Also, the proxy sends result sets back to the client. So, the proxy might be a bottleneck in your cases as well as overall network throughput. Check that the proxy server doesn&#x27;t overutilize CPUs and doesn&#x27;t have any &lt;a href=&quot;https://apacheignite.readme.io/docs/preparing-for-production&quot; rel=&quot;nofollow noreferrer&quot;&gt;issues related to garbage collection or memory utilization&lt;/a&gt;. The proxy won&#x27;t be needed in Ignite 2.8 any longer.&lt;/p&gt;&lt;p&gt;Anyway, the fastest way to preload data in Ignite is with the usage of IgniteStreaming APIs. Those are not available for Python yet but a Java application is pretty straightforward. You can use &lt;a href=&quot;https://github.com/apache/ignite/blob/master/examples/src/main/java/org/apache/ignite/examples/datagrid/CacheDataStreamerExample.java&quot; rel=&quot;nofollow noreferrer&quot;&gt;this example&lt;/a&gt; as a reference by putting your records into the streamer with key-value APIs.&lt;/p&gt;&lt;p&gt;If you&#x27;d like to continue using SQL INSERTS then use either JDBC or ODBC driver together with &lt;a href=&quot;https://apacheignite-sql.readme.io/docs/set&quot; rel=&quot;nofollow noreferrer&quot;&gt;SET STREAMING&lt;/a&gt; command.&lt;/p&gt;</Body>
</answer>
</qroot>
