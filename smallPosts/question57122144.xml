<?xml version="1.0" encoding="utf-8"?>
<qroot>
<question>
<Title>Separate one big dictionary into smaller dictionaries inside a list</Title>
<Body>&lt;p&gt;Let us say I have a dictionary with 1000 key-values&lt;/p&gt;&lt;pre&gt;&lt;code&gt;x = {1: &#x27;a&#x27;, 2: &#x27;b&#x27;, 3: &#x27;c&#x27;, 4: &#x27;d&#x27;, 5: &#x27;e&#x27;, 6: &#x27;f&#x27;, ....}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I would like to convert it into&lt;/p&gt;&lt;pre&gt;&lt;code&gt;x = [{1: &#x27;a&#x27;, 2: &#x27;b&#x27;, 3: &#x27;c&#x27;, ...}, {10: &#x27;z&#x27;, 11: &#x27;z&#x27;, 12: &#x27;z&#x27;, ...}]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I am wondering if python has built-in function for this. Also my concern is on scaling.. Let us say I have 1 million key-values on a dictionary then I would like it to be separated via 1000 key-values in a list&lt;/p&gt;</Body>
<Tags>python,python-3.x,parallel-processing</Tags>
</question>
<answer>
<Body>&lt;p&gt;With that many values I would consider using generator to produce the chunks. It greatly depends what are you going to do with them (do you need all of them at the same time or you process one chunk at a time):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# create some dictionaryx = {i: &#x27;z&#x27; + str(i) for i in range(1, 22+1)}def get_chunks(x, size=10):    out = {}    for i, k in enumerate(x, 1):        if i % size == 0:            yield out            out = {}        out[k] = x[k]    # last chunk:    if out:        yield outfor chunk in get_chunks(x):    print(chunk)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Prints:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;{1: &#x27;z1&#x27;, 2: &#x27;z2&#x27;, 3: &#x27;z3&#x27;, 4: &#x27;z4&#x27;, 5: &#x27;z5&#x27;, 6: &#x27;z6&#x27;, 7: &#x27;z7&#x27;, 8: &#x27;z8&#x27;, 9: &#x27;z9&#x27;}{10: &#x27;z10&#x27;, 11: &#x27;z11&#x27;, 12: &#x27;z12&#x27;, 13: &#x27;z13&#x27;, 14: &#x27;z14&#x27;, 15: &#x27;z15&#x27;, 16: &#x27;z16&#x27;, 17: &#x27;z17&#x27;, 18: &#x27;z18&#x27;, 19: &#x27;z19&#x27;}{20: &#x27;z20&#x27;, 21: &#x27;z21&#x27;, 22: &#x27;z22&#x27;}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To put the results inside list:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;print(list(get_chunks(x)))&lt;/code&gt;&lt;/pre&gt;</Body>
</answer>
<answer>
<Body>&lt;p&gt;You can use the grouper recipe from &lt;a href=&quot;https://docs.python.org/3/library/itertools.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;code&gt;itertools&lt;/code&gt;&lt;/a&gt; (substitute &lt;code&gt;10&lt;/code&gt; with any chunk size you desire):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;list(map(dict, zip(*[iter(x.items())] * 10)))&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you are only going to iterate through the sequence of subdicts, however, you don&#x27;t need the costly conversion to a list as your question suggests, in which case you can simply iterate through the iterable returned by the &lt;code&gt;map&lt;/code&gt; function instead, so that it would be both time and memory-efficient:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;for chunk in map(dict, zip(*[iter(x.items())] * 10)):    print(chunk)&lt;/code&gt;&lt;/pre&gt;</Body>
</answer>
<answer>
<Body>&lt;p&gt;A straight forward, and super-ugly answer to your question is something like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import itertoolsdef slice_it_up(d, n):    return [{x for x in itertools.islice(d.items(), i, i+n)} for i in range(0, len(d), n)]d = {&#x27;key1&#x27;: 1, &#x27;key2&#x27;: 2, &#x27;key3&#x27;: 3, &#x27;key4&#x27;: 4, &#x27;key5&#x27;: 5}dd = slice_it_up(d, 3)print(dd)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This prints&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[{(&#x27;key2&#x27;, 2), (&#x27;key1&#x27;, 1), (&#x27;key3&#x27;, 3)}, {(&#x27;key5&#x27;, 5), (&#x27;key4&#x27;, 4)}]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is by any means not something that should be actually done, though. As the first answer already mentioned, you should really use generators to produce the chunks.&lt;/p&gt;&lt;p&gt;Since you&#x27;ve mentioned some kind of parallel processing (hope you aren&#x27;t going to learn what python&#x27;s GIL is at that stage, Google it, and see if you are going to be hit by that), at the very least you really don&#x27;t have to aggregate the itertools.islice result (which is a generator) into a big fat list, but send those straight into processing instead.&lt;/p&gt;</Body>
</answer>
</qroot>
