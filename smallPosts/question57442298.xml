<?xml version="1.0" encoding="utf-8"?>
<qroot>
<question>
<Title>PyTorch: Why does validation accuracy change once calling it inside or outside training epochs loop?</Title>
<Body>&lt;p&gt;Hi I am learning deep learning and I am trying to use the RNN with train, test and validation sets on time series finance data. Below is my code : &lt;/p&gt;&lt;pre&gt;&lt;code&gt;def get_lr(optimizer):    for param_group in optimizer.param_groups:        return param_group[&#x27;lr&#x27;]# In[63]:def train_model(epoch, model, optimizer, train_loader):    model.train()    t0 = time.time()    correct = 0    total = 0    final_loss = 0    for batch_idx, (X,labels) in enumerate(train_loader):        data,labels = map(lambda x: Variable(x), [X,labels])        optimizer.zero_grad()        output = model(data)        device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)        ##print(&#x27;device : &#x27;, device)        final_output=output.to(device)        loss = F.cross_entropy(final_output, labels)        final_loss += loss.item()        loss.backward()        optimizer.step()        print(&#x27;predicted labels&#x27;,final_output.squeeze())        #print(&#x27;Actual labels&#x27;,labels.squeeze())        print(&#x27;Train Epoch: {} Batch: {} [{}/{} ({:.2f}%, time:{:.2f}s)]\tBatch Loss: {:.6f}&#x27;.format(                epoch, batch_idx, batch_idx * len(data), len(train_loader.dataset),                100. * batch_idx / len(train_loader), time.time() - t0,                final_loss))                ##avg_loss))        _, predicted = torch.max(output.data, 1)        total += labels.size(0)        correct += (predicted == labels).sum().item()        t0 = time.time()    final_loss /= (batch_idx+1)    accuracy =  100*correct/total    lr = get_lr(optimizer)    learning_rates.append(lr)    print(&#x27;Training Accuracy : &#x27;,accuracy)    print(&#x27;Training Loss : &#x27;,final_loss)    print(&#x27;Learning Rate : &#x27;,lr)    if epoch%epoch_interval == 0 or epoch ==1 or epoch == epochs:         path = base_path + &#x27;models/RNN/rnn_&#x27;        torch.save(model,path+str(epoch)+&#x27;.pth&#x27;)        ##torch.save(model,path)        print(&#x27;model saved&#x27;)    if epoch%plot_epoch_interval == 0 or epoch ==1 or epoch == epochs:         epochs_list.append(epoch)        train_loss.append(final_loss)        train_accuracies.append(accuracy)    return lr,final_loss,accuracy# In[166]:def validate(epoch,model, val_loader,optimizer):    model.eval()    val_loss = 0    correct = 0    total = 0    loss = 0    ypred,ytrue,scores = [],[],[]    for batch_idx,(X,labels) in enumerate(val_loader):        data,labels = map(lambda x: Variable(x), [X,labels])        output = model(data)        device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)        final_val_output=output.to(device)        val_loss += F.cross_entropy(final_val_output, labels)  # sum up batch loss        _, predicted = torch.max(output.data, 1)        total += labels.size(0)        correct += (predicted == labels).sum().item()        ypred.extend(predicted.tolist())        ytrue.extend(labels.tolist())        scores.extend(output.tolist())    val_loss /= (batch_idx+1)    accuracy =  100*correct/total    if epoch%plot_epoch_interval == 0 or epoch ==1 or epoch == epochs:         validation_loss.append(val_loss.item())        val_accuracies.append(accuracy)    print(&#x27;Accuracy : &#x27;,accuracy)    print(&#x27;\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\n&#x27;.format(        val_loss, correct,total,accuracy))    print(&quot;==============================================&quot;)    return &quot;{:.4f}%&quot;.format(100.* correct / total), accuracy,loss,ypred,ytrue,scores# In[276]:def test(data_loader,model):    torch.manual_seed(1)    np.random.seed(1)    #data_loader = DataLoader(FinancialData(xtest,ytest), batch_size = batch_size, shuffle = False)    model = torch.load(path)    model.eval()    for params in model.parameters():         print(params)    val_loss = 0    correct = 0    total = 0    loss = 0    ypred,ytrue,scores = [],[],[]    with torch.no_grad():        for batch_idx,(X,labels) in enumerate(data_loader):            data,labels = map(lambda x: Variable(x), [X,labels])            output = model(data)            _, predicted = torch.max(output.data, 1)            total += labels.size(0)            correct += (predicted == labels).sum().item()            ypred.extend(predicted.tolist())            ytrue.extend(labels.tolist())            scores.extend(output.tolist())            accuracy =  100*correct/total    print(&#x27;Test Accuracy : &#x27;,accuracy)# In[288]:def train_on_batch(lr,epochs,momentum,X_train,Y_train,X_val,Y_val,batch_size):    cuda=False    seed=1    torch.manual_seed(seed)    train_loader = DataLoader(FinancialData(X_train,Y_train),batch_size=batch_size,shuffle=True)     val_loader = DataLoader(FinancialData(X_val,Y_val),batch_size=batch_size,shuffle=False)     test_loader = DataLoader(FinancialData(X_test_new,Y_test), batch_size = batch_size, shuffle = False)    input_size = 1    hid_size = 10    num_layers = 2    num_classes = len(np.unique(Y_train))    dropRate = 0.0    bidirection = True    model = Network(input_size=input_size,hid_size =hid_size,window_size = window_size,num_layers=num_layers,                num_classes=num_classes,dropRate = dropRate,bidirection=bidirection)    ypred,ytrue, scores = [],[],[]    for params in model.parameters():        print(params)    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=False)    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,&#x27;max&#x27;, factor=0.25, patience=6, verbose=True,                                                            threshold_mode=&#x27;abs&#x27;, threshold=0.01, min_lr=1e-6)    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, &#x27;max&#x27;, factor=0.5, patience=5,    #                                                       verbose=True,threshold_mode=&#x27;abs&#x27;, threshold=0.01,     #                                                       min_lr=1e-6)    path = base_path + &#x27;models/RNN/rnn_best_model.pth&#x27;    best_val_loss = 0    best_val_acc = 0    best_epoch = 0    best_lr = lr    best_tr_acc = 0    for epoch in range(1, epochs + 1):        tuned_lr,tr_loss,tr_acc = train_model(epoch, model, optimizer, train_loader)        acc_str, val_acc, val_loss, ypred, ytrue, scores = validate(epoch,model,val_loader,optimizer)        if val_acc &amp;gt;= best_val_acc:                torch.save(model,path)                #best_val_loss = val_loss                best_val_acc = val_acc                best_epoch = epoch                best_lr = tuned_lr                best_tr_acc = tr_acc        scheduler.step(val_acc)        #scheduler.step(tr_acc)        print(&#x27;=&#x27;*100)#         for params in model.parameters():#             print(params)#         print(&#x27;=&#x27;*100)    test(val_loader,model)    test(test_loader,model)    #validate(epoch,model,val_loader,optimizer)    #validate(epoch,model,test_loader,optimizer)    print(&#x27;best epoch : {}, best_lr : {}, best_tr_acc : {}, best val_acc : {:.4f}\n&#x27;.format(best_epoch,best_lr,best_tr_acc,best_val_acc))        scores = np.asarray(scores)    return tr_acc,val_acc, ypred, ytrue, scores# In[289]:cuda=torch.cuda.is_available()X_train,Y_train,X_val,Y_val,X_test,Y_test = splitDataWithVal(feat_wise_data,labels_new,test_size=0.2,val_size=0.25)X_train_new, X_val_new, X_test_new = standardizeDataVal(X_train, X_test, X_val, mode = &#x27;Normalizer&#x27;) # # Check for Class Imbalance# In[292]:Ytrain_df= pd.DataFrame(Y_train,columns=[0])print(Ytrain_df.shape)print(Ytrain_df.columns)print(Ytrain_df.groupby(0).size())train_loss = []validation_loss = []epochs_list = []train_accuracies = []val_accuracies = []learning_rates = []epoch_interval = 1#10plot_epoch_interval = 5lr = 0.01momentum = 0.9epochs = 3batch_size = 4print(&#x27;batch_size : &#x27;,batch_size)tr_acc,val_acc, ypred, ytrue, scores = train_on_batch(lr,epochs,momentum,X_train_new,Y_train,X_val_new,Y_val,batch_size)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I tested it for 3 epochs and saved models after every epoch. However, after 3rd epoch i.e. complete 3 epochs of training, when I test my model by calling test() function of my code, it gives &lt;strong&gt;49.7% validation accuracy&lt;/strong&gt; and &lt;strong&gt;59.3% test accuracy&lt;/strong&gt;. Whereas if I use validate() function of my code, it gives &lt;strong&gt;51.146% validation accuracy&lt;/strong&gt; when called after 3rd epoch of training within training loop. Using validate() function after complete training of 3 epochs ie. outside for loop, I get &lt;strong&gt;49.12% validation accuracy&lt;/strong&gt; and &lt;strong&gt;54.0697% test accuracy&lt;/strong&gt;. &lt;/p&gt;&lt;p&gt;Why does validation accuracy change calling the same validate function twice i.e. once inside training epochs loop and other time after training epochs loop ? Also, Which function is correct way of testing and validating, validate() or test()?  &lt;/p&gt;&lt;p&gt;I even loaded all the models which I am saving after every epoch and checked their weights which are same as what they were seen during training. Please help as I am new to this domain. &lt;/p&gt;</Body>
<Tags>python,validation,testing,deep-learning,pytorch</Tags>
</question>
<answer>
<Body>&lt;ol&gt;&lt;li&gt;It is &lt;a href=&quot;https://www.researchgate.net/post/Whenever_i_run_my_neural_network_I_get_different_result&quot; rel=&quot;nofollow noreferrer&quot;&gt;not unusual&lt;/a&gt; to get different accuracies every time you run your code because the parameters are randomly initialised when the training starts. The algorithms AI algorithms are &lt;a href=&quot;https://machinelearningmastery.com/randomness-in-machine-learning/&quot; rel=&quot;nofollow noreferrer&quot;&gt;stochastic&lt;/a&gt; is nature i.e the models are &lt;a href=&quot;https://stackoverflow.com/questions/5891727/randomness-in-artificial-intelligence-machine-learning&quot;&gt;naturally dependent&lt;/a&gt; on randomness.&lt;/li&gt;&lt;li&gt;Even I&#x27;m a new learner and had faced such doubts, even got confused between &lt;code&gt;Validation&lt;/code&gt; and &lt;code&gt;Test&lt;/code&gt; datasets. For testing the accuracy of the trained model use the &lt;code&gt;test()&lt;/code&gt; function. &lt;a href=&quot;https://machinelearningmastery.com/difference-test-validation-datasets/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Use the &lt;code&gt;validation()&lt;/code&gt;&lt;/a&gt; function to give an unbiased estimate of the skill of the final tuned model when comparing or selecting between final models.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;==========EDIT-1==========&lt;/p&gt;&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;So when you call the &lt;code&gt;validate()&lt;/code&gt; function inside training loop it returns the accuracy calculated for &lt;strong&gt;only&lt;/strong&gt; the &lt;strong&gt;third&lt;/strong&gt; i.e the last epoch, and when you call the same &lt;code&gt;validate()&lt;/code&gt; function after the training loop, the accuracy is calculated using the data it has &lt;em&gt;seen&lt;/em&gt; through &lt;strong&gt;all&lt;/strong&gt; the epochs. Try printing your &lt;em&gt;correct&lt;/em&gt; variable so that you’ll notice the reason behind the accuracies! :)&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Hope I&#x27;m clear in my explanation and do note that &lt;code&gt;validation&lt;/code&gt; &lt;strong&gt;does not learn&lt;/strong&gt; the dataset but &lt;a href=&quot;https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;code&gt;only sees&lt;/code&gt;&lt;/a&gt; (i.e. fine-tune) it. Refer my point 2 and the links in point 2 for your second part of the question. &lt;/p&gt;</Body>
</answer>
</qroot>
